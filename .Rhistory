devtools::install_github(c('rstudio/rmarkdown', 'rstudio/bookdown'))
devtools::install_github(c('rstudio/rmarkdown', 'rstudio/bookdown'), force = TRUE)
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
library(purrr)
list("01a", "01b") %>%
invoke(paste, ., sep = "-")
map(.x, .f, ...)
library(purrr)
invoke(runif, list(n = 10))
invoke(shapiro.test, iris)
urls <- read_html("https://en.wikipedia.org/wiki/R_(programming_language)") %>%
html_nodes("a") %>%
html_attr("href")
library(purrr)
urls <- read_html("https://en.wikipedia.org/wiki/R_(programming_language)") %>%
html_nodes("a") %>%
html_attr("href")
# Get the list of the urls
library(rvest)
urls <- read_html("https://en.wikipedia.org/wiki/R_(programming_language)") %>%
html_nodes("a") %>%
html_attr("href")
urls
head(urls)
library(httr)
map(urls, ~ GET(.x) %>% status_code(.x)) %>%
every(.x == 200)
map(urls, ~ GET(.x) %>% status_code()) %>%
every(.x == 200)
map(urls, ~ GET(.x))
urls <- read_html("https://en.wikipedia.org/wiki/R_(programming_language)") %>%
html_nodes("a") %>%
html_attr("href")
head(urls)
urls <- read_html("https://cran.r-project.org/web/views/") %>%
html_nodes("a") %>%
html_attr("href")
head(urls)
map(urls, ~ GET(.x))
safe_get <- safe_get(GET)
safe_get <- safely(GET)
map(urls, ~ safe_get(.x))
urls <- read_html("https://cran.r-project.org/mirrors.html") %>%
html_nodes("a") %>%
html_attr("href")
head(urls)
map(urls, ~ GET(.x))
safe_get <- possibly(GET, 400)
safe_get <- possibly(GET, 400)
map(urls, safe_get) %>%
every(.x != 200)
head(airquality)
map(airquality, shapiro.test) %>% keep(~ .x$p.value > 0.05)
library(purrr)
map(airquality, shapiro.test) %>% keep(~ .x$p.value > 0.05)
map_if(iris, is.numeric, shapiro.test)
library(tidystringdist) # Works since v0.1.2
library(tidystringdist) # Only with v0.1.2 and further
tidy_comb_all(names(airquality)) %>%
pmap(~ cor.test(airquality[[.x]], airquality[[.y]])) %>%
map_df(broom::tidy) %>%
cbind(comb, .)
bookdown:::serve_book()
library(purrr)
library(tidystringdist) # Works since v0.1.2
comb <- tidy_comb_all(names(airquality))
pmap(comb, ~ cor.test(airquality[[.x]], airquality[[.y]])) %>%
map_df(broom::tidy) %>%
cbind(comb, .)
bookdown:::serve_book()
bookdown:::serve_book()
library(dplyr)
comb <- tidy_comb_all(names(airquality))
res <- pmap(comb, ~ cor.test(airquality[[.x]], airquality[[.y]])) %>%
map_df(broom::tidy) %>%
cbind(comb, .)
knitr::kable(res)
bookdown:::serve_book()
res <- pmap(comb, ~ lm(airquality[[.x]] ~ airquality[[.y]]))
get_rsquared <- compose(as_mapper(~ .x$r.squared), summary)
map_dbl(res, get_rsquared)
res <- pmap(comb, ~ lm(airquality[[.x]] ~ airquality[[.y]]))
get_rsquared <- compose(as_mapper(~ .x$r.squared), summary)
map_dbl(res, get_rsquared)
get_rsquared <- compose("r.squared", summary)
get_rsquared <- compose(~ "r.squared", summary)
map_dbl(res, get_rsquared)
get_rsquared <- compose(as_mapper(~ .x$r.squared), summary)
map_dbl(res, get_rsquared)
map_dbl(res, get_rsquared) %>% detect_index(~ .x > 0.5)
res <- pmap(comb, ~ lm(airquality[[.x]] ~ airquality[[.y]]))
get_rsquared <- compose(as_mapper(~ .x$r.squared), summary)
map_dbl(res, get_rsquared) %>% detect_index(~ .x > 0.5)
map_dbl(res, get_rsquared) %>% some(~ .x > 0.5)
download.file("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv", "titanic.csv")
# From http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv
titanic <- read_csv("titanic.csv")
# From http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv
titanic <- readr::read_csv("titanic.csv")
# From http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv
titanic <- readr::read_csv("titanic.csv")
train <- rerun(20, sample_frac(titanic, size = 0.8))
validation <- map(train, ~ anti_join(titanic, .x))
rpart_pimped <- partial(rpart, formula = survived ~ sex, method = "class")
res <- map(train, ~ rpart_pimped(data = .x))
rpart_pimped <- partial(rpart, formula = survived ~ sex, method = "class")
rpart_pimped <- partial(rpart::rpart, formula = survived ~ sex, method = "class")
res <- map(train, ~ rpart_pimped(data = .x))
res
res[[1]]
res <- map(train, rpart_pimped)
res[[1]]
map_dbl(conf_mats, ~ .x$byClass["Specificity"]) %>% detect_index(~ .x > 0.7)
conf_mats
map_dbl(conf_mats, ~ .x$byClass["Specificity"])
map_dbl(conf_mats, ~ .x$byClass["Specificity"]) %>% detect_index(~ .x > 0.7)
sens <- map_dbl(conf_mats, ~ .x$byClass["Sensitivity"]) %>% detect_index(~ .x > 0.7)
spec <- map_dbl(conf_mats, ~ .x$byClass["Specificity"]) %>% detect_index(~ .x > 0.7)
keep(sens, map_lgl(sens, ~ .x %in% spec))
set.seed(2811)
# From http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv
titanic <- readr::read_csv("titanic.csv")
train <- rerun(20, sample_frac(titanic, size = 0.8))
validation <- map(train, ~ anti_join(titanic, .x))
rpart_pimped <- partial(rpart::rpart, formula = survived ~ sex, method = "class")
res <- map(train, rpart_pimped)
res[[1]]
prediction <- map2(validation, res, ~ predict(.y, .x, type = "class"))
w_prediction <- map2(validation, prediction, ~ mutate(.x, prediction = .y))
conf_mats <- map(w_prediction, ~ confusionMatrix(.x$prediction, .x$survived))
sens <- map_dbl(conf_mats, ~ .x$byClass["Sensitivity"]) %>% detect_index(~ .x > 0.7)
spec <- map_dbl(conf_mats, ~ .x$byClass["Specificity"]) %>% detect_index(~ .x > 0.7)
keep(sens, map_lgl(sens, ~ .x %in% spec))
spec <- map_dbl(conf_mats, ~ .x$byClass["Specificity"]) %>% detect_index(~ .x > 0.6)
keep(sens, map_lgl(sens, ~ .x %in% spec))
sens
spec
map_dbl(conf_mats, ~ .x$byClass["Sensitivity"])
map_dbl(conf_mats, ~ .x$byClass["Sensitivity"])
sens <- map_dbl(conf_mats, ~ .x$byClass["Sensitivity"]) %>% keep_index(~ .x > 0.85)
keep_index <- function(.x, .p, ...) {
sel <- purrr:::probe(.x, .p, ...)
which(sel)
}
sens <- map_dbl(conf_mats, ~ .x$byClass["Sensitivity"]) %>% keep_index(~ .x > 0.85)
spec <- map_dbl(conf_mats, ~ .x$byClass["Specificity"]) %>% keep_index(~ .x > 0.7)
keep(sens, map_lgl(sens, ~ .x %in% spec))
map_lgl(sens, ~ .x %in% spec)
sens
conf_mats <- map(w_prediction, ~ confusionMatrix(.x$prediction, .x$survived))
conf_mats
sens <- map_dbl(conf_mats, ~ .x$byClass["Sensitivity"]) %>% keep_index(~ .x > 0.85)
spec <- map_dbl(conf_mats, ~ .x$byClass["Specificity"]) %>% keep_index(~ .x > 0.7)
keep(sens, map_lgl(sens, ~ .x %in% spec))
bookdown:::serve_book()
library(broom)
library(dplyr)
library(purrr)
tidy_lm(Sepal.Length ~ Species, data = iris)
tidy_lm <- compose(tidy, lm)
tidy_lm(Sepal.Length ~ Species, data = iris)
tidy_lm(Sepal.Length ~ Species, data = iris) %>% sort()
tidy_lm <- compose(arrange, tidy, lm)
tidy_lm(Sepal.Length ~ Species, data = iris)
tidy_lm <- compose(tidy, lm)
tidy_lm(Sepal.Length ~ Species, data = iris)
tidy_lm <- compose(tidy, lm)
tidy_lm(Sepal.Length ~ Species, data = iris)
mean_na_rm <- partial(mean, na.rm = TRUE)
mean_na_rm(airquality$Ozone)
is_not_numeric <- negate(is.numeric)
is_not_numeric("this")
bookdown:::serve_book()
# Returns a dbl
map_dbl(1:10, ~ .x + 1)
# Returns a dbl
map_dbl(1:10, sqrt)
ls("map_", envir = "package:purrr")
ls(name = "package:purrr", pattern = "map_")
ls(name = "package:purrr", pattern = "^map_")
map2_chr(letters, LETTERS, paste)
map_dbl(1:10, ~ .x + 2)
l <- list(a = 1:3, b = 2:4, c = 3:5)
pmap(l, ~ ..1 + ..2 + ..3)
pmap_dbl(l, ~ ..1 + ..2 + ..3)
walk(1:10, print)
walk(1:10, plot)
walk(1:2, plot)
regex_build <- function(list){
reduce(list, ~ paste(.x, .y, sep = "|"))
}
regex_build <- function(list){
reduce(list, ~ paste(.x, .y, sep = "|"))
}
regex_build("one","two","three")
reg <- c("one","two","three")
regex_build(reg)
#reg <- c("one","two","three")
regex_build("one","two","three")
regex_build <- function(...){
reduce(..., ~ paste(.x, .y, sep = "|"))
}
#reg <- c("one","two","three")
regex_build("one","two","three")
regex_build("one","two","three")
regex_build <- function(...){
reduce(list(...), ~ paste(.x, .y, sep = "|"))
}
regex_build("one","two","three")
paste("one", paste("two", "three", sep = "|")), sep = "|"))
paste("two", "three", sep = "|"))
paste("two", "three", sep = "|"))
paste("two", "three", sep = "|")
paste("one", paste("two", "three", sep = "|"), sep = "|")
regex_build("one","two","three", "four")
list.files(pattern = "Rmd")
length(list.files(pattern = "Rmd"))
length(list.files(pattern = "Rmd")) - 2
library(tidyverse)
library(rvest)
library(httr)
GET('http://www.404errorpages.com')
urls <- c("http://colinfay.me", "http://thinkr.fr", "http://randomsadressthatdoesntexistsihope.org")
status_code("http://www.404errorpages.com")
get_status <- compose(status_code, GET)
map(urls, get_status)
GET(""http://randomsadressthatdoesntexistsihope.org"")
GET("http://randomsadressthatdoesntexistsihope.org")
GET("orpk")
urls <- c("http://colinfay.me", "http://thinkr.fr", "randomsadressthatdoesntexistsihope")
get_status <- compose(status_code, GET)
map(urls, get_status)
urls <- c("http://colinfay.me", "http://thinkr.fr", "reallynotanadress")
get_status <- compose(status_code, GET)
map(urls, get_status)
get_status("colinfay.me")
map(urls, get_status) %>% every(~ .x == 200)
urls <- c("http://colinfay.me", "http://thinkr.fr", "reallynotanadress")
get_status <- compose(status_code, GET)
map(urls, get_status) %>% keep(~ .x == 200)
map(urls, get_status) %>% set_names(nm = urls) %>% keep(~ .x == 200)
get_h1 <- compose(html_text,
as_mapper(~ html_nodes(.x, "h1")),
read_html)
get_h1("http://thinkr.fr")
urls <- c("http://colinfay.me", "http://thinkr.fr")
map(urls, get_h1) %>% set_names(urls)
get_h2 <- compose(html_text,
as_mapper(~ html_nodes(.x, "h2")),
read_html)
urls <- c("http://colinfay.me", "http://thinkr.fr")
map(urls, get_h2) %>% set_names(urls)
# http status code error
GET("notexistingurl")
# Error because host doesn't exist
GET("notexistingurl.org")
possible_read <- possibly(read_html, otherwise = NULL)
possible_read <- possibly(read_html, otherwise = NULL)
map(urls, possible_read) %>% compact()
map(urls, possible_read) %>% set_names(urls) %>% compact()
bookdown:::serve_book()
bookdown:::serve_book()
files <- list.files(, pattern = "csv", full.names = TRUE)
files <- list.files("../open-data/", pattern = "^2017", full.names = TRUE) %>%
set_names(basename(.))
full <- map_df(files, read_csv, .id = "file")
files
files <- list.files(pattern = "csv", full.names = TRUE) %>%
set_names(basename(.))
full <- map_df(files, read_csv, .id = "file")
files
l <- c(1, 2, 3, NA, "a", 4, "b", NA)
discard(l, is.na)
l <- list(list(1:10, 1:20), list(20:30, 40:50))
modify_depth(l, 2, ~ append(.x, sum(.x)))
modify_depth(l, 2, ~ prepend(.x, sum(.x)))
lifted_is_na <- lift_ld(is.na)
lifted_is_na(1,2,3,NA)
collapse("one","two","three", "four")
l <- list(rnorm(10), rnorm(10), rnorm(1000))
?mean
pmap(list(numbers, trim, na_rm), mean)
numbers <- list(rnorm(10), rnorm(10), rnorm(1000))
trim <- 20
na_rm <- TRUE
pmap(list(numbers, trim, na_rm), ~ mean(..1, ..2,..3))
pmap_dbl(list(numbers, trim, na_rm), ~ mean(..1, ..2,..3))
.rs.restartR()
l <- 1:100
detect_index(l, ~ sqrt(.x) == 3)
l <- 22:143
detect_index(l, ~ sqrt(.x) == 9)
head_while(l, ~ sqrt(.x) == 9)
head_while(l, ~ sqrt(.x) < 9)
# Random words from https://www.randomlists.com/random-words
words <- c("copper", "explain", "ill-fated", "truck", "neat","unite","branch","educated","tenuous", "hum","decisive","notice")
# Extract words that end with a "e"
my_regex <- "e$"
keep(words, ~ grepl(my_regex, .x))
hash <- list(tweet1 = c("#RStats", "#Datascience"), tweet2 = c("#RStats", "#BigData"))
simplify(hash)
simplify(hash) %>% paste(collapse = " ")
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
bookdown:::serve_book()
knitr:::is_html_output()
bookdown:::serve_book()
r if (knitr:::is_html_output()) '# References {-}'
knitr::write_bib(c(
.packages(), 'bookdown', 'knitr', 'rmarkdown', 'purrr'
), 'packages.bib')
json_file <- jsonlite::read_json("test.json")
json_file
json_file <- jsonlite::read_json("test.json")
bookdown:::serve_book()
json_file <- jsonlite::read_json("test.json")
json_file
map(json_file, "obs")
map(json_file, "obs", "value")
json_file
map(json_file, "value")
jsonlite::read_json(text = '[
{
"id": "066062",
"name": "Observatory Hill",
"label": "Sydney City",
"tz": "Australia/Sydney",
"record_start": "1910",
"record_end": "2017"
},
{
"id": "067105",
"name": "Richmond RAAF",
"label": "Sydney West",
"tz": "Australia/Sydney",
"record_start": "1939",
"record_end": "2017"
}
]')
json_object <- '[
{
"id": "066062",
"name": "Observatory Hill",
"label": "Sydney City",
"tz": "Australia/Sydney",
"record_start": "1910",
"record_end": "2017"
},
{
"id": "067105",
"name": "Richmond RAAF",
"label": "Sydney West",
"tz": "Australia/Sydney",
"record_start": "1939",
"record_end": "2017"
}
]'
a <- tempdir()
write(json_object, "a.json")
a <- jsonlite::fromJSON(file.path(a, "a.json"))
write(json_object, file.path(a, "a.json"))
a <- jsonlite::fromJSON(file.path(a, "a.json"))
stations %>% pluck(3, "name")
stations <- jsonlite::fromJSON(file.path(a, "a.json"))
a <- tempdir()
write(json_object, file.path(a, "a.json"))
stations <- jsonlite::fromJSON(file.path(a, "a.json"))
stations %>% pluck(3, "name")
stations = fromJSON("https://goo.gl/U7C3MP")
stations = jsonlite::fromJSON("https://goo.gl/U7C3MP")
stations %>% pluck(3, "name")
map(stations, "name")
map(stations, 3, "name")
stations %>% pluck(3, "name")
map_chr(stations, 3, "name")
map(stations, "name")
stations %>% map(~ pluck(., "name"))
stations = jsonlite::fromJSON("https://goo.gl/U7C3MP")
map(stations, "name")
stations %>% map(~ pluck(., "name"))
stations
stations = RJSON::fromJSON("https://goo.gl/U7C3MP")
stations = RJSONIO::fromJSON("https://goo.gl/U7C3MP")
map(stations, "name")
stations %>% map(~ pluck(., "name"))
stations
stations %>% map(~ pluck(., "name"))
library(tidyverse)     # purrr is in here!
library(RJSONIO)
library(tidyverse)     # purrr is in here!
library(RJSONIO)
stations = fromJSON("https://goo.gl/U7C3MP")
str(stations)
stations[[3]]
stations[[3]][["name"]]
stations %>% pluck(3, "name")
stations %>% map(~ pluck(., "name"))
stations %>% pluck(3, "name")
stations
stations %>% pluck(3, "name")
stations %>%
map(pluck, "name") %>%
unlist()
stations = fromJSON("https://goo.gl/U7C3MP")
stations = fromJSON("https://goo.gl/U7C3MP")
str(stations)
stations %>% pluck(3, "name")
stations %>% purrr::pluck(3, "name")
unloadNamespace(rvest)
unloadNamespace("rvest")
stations %>% purrr::pluck(3, "name")
json_file <- jsonlite::read_json("test.json")
map(json_file, "value")
library(purrr)
map(json_file, "value")
map(json_file, "id")
map_df(json_file, "id")
map_df(json_file, "id", "test1")
map_df(json_file, "id", "test1")
map_df(json_file, "id")
map(json_file, "id", "test1")
map(json_file, test1")
map(json_file, "test1")
map(json_file, ~ "id", "test1")
map(json_file, ~ pluck(.x, "id", "test1"))
map(json_file, "Res", "test1")
map(json_file, ~ pluck(.x, "Res", "test1"))
