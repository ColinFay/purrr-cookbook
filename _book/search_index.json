[
["index.html", "purrr cookbook Welcome", " purrr cookbook Colin Fay Last update on: 2018-01-19 Welcome This “cookbookdown” covers a series of common receipes you can do with {purrr}. It’s based on several blogposts written on colinfay.me, some {purrr} code shared on Twitter, and on some use-cases found or fought in the wild wild data world. As with any cookbook, this bookdwon is not intended at explaining in details what {purrr} does or how the functions used works. There is a short discussion after each receipes to quickly explain what the code does, but we won’t go into specific details about each piece of code. For example, you won’t find an explanation on the Shapiro Test in the chapter talking about this test. I also try to include (as much as possible) references to other articles / blogposts / books that can help you go deeper. And if ever you need more explanation, reach me on Twitter! "],
["how-to-read-this-book.html", "How to read this book Who is this cookbook for? Before reading You want another receipe You want to share a receipe What to do if you find a typo", " How to read this book This book is divided in 5 chapters. Each chapter contains a random number of receipes, more or less from the easiest to more complex examples. “Statistics” contains a list of useful common stat tricks with {purrr} “Webmining” gives you elements to mine info from the web (HTML / JSON) “Text Wrangling” covers some text mining methods “Code optimisation” is a chapter about using {purrr} to write better code “Data Wrangling” is a list of receipes I couldn’t fit anywhere else ¯\\(ツ)/¯ Based on other programming cookbook template, each receipe is divided as such: “I want to…”: what you want to do “Here’s how to”: how to do this “Ok, but why?”: more explanations about the solution “See also”: further references if you want to go deeper Who is this cookbook for? Anybody interested in learning more about {purrr}, either by reading this from cover to cover (well… figuratively speaking), of by picking what you find interesting. Before reading We expect the reader to be a little bit familiar with R, and with the core packages from the tidyverse. Copy and paste the below code to be sure you have all the packages you need. install.packages(&quot;tidyverse&quot;) install.packages(&quot;broom&quot;) install.packages(&quot;rvest&quot;) install.packages(&quot;attempt&quot;) install.packages(&quot;tidystringdist&quot;) install.packages(&quot;tidytext&quot;) Let’s launch the tidyverse to be sure we have everything we need: library(tidyverse) You want another receipe For another receipe, please ask on this issue. You want to share a receipe I’ll be glad to add other {purrr} receipes, so if ever you want to share one (or more), feel free to make a PR on the GitHub repo. What to do if you find a typo Nobody’s perfect and this book might contains typos. So please, yes please, open a PR (or feel free to reach me on Twitter) "],
["intro.html", "Chapter 1 purrr basics 1.1 map function 1.2 map_* functions 1.3 Mappers 1.4 map on 2 elements 1.5 map on more elements 1.6 Iteration for side effect", " Chapter 1 purrr basics 1.1 map function 1.1.1 I want to… Start using {purrr}. 1.1.2 Here’s how to: The base skeleton of {purrr} iteration functions are: library(purrr) map(.x, .f, ...) 1.1.3 Ok, but why? In this skeleton: .x is a list, a data.frame or a vector. .f is the function, formula or atomic vector that will be applied on each element of .f. Here, what map does is applying the function to each element of a list. The returned object is always a list. 1.1.4 See also A introduction to purrr 1.2 map_* functions 1.2.1 I want to… Control the output of my iterations. 1.2.2 Here’s how to: # Returns a dbl map_dbl(1:10, sqrt) ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 ## [8] 2.828427 3.000000 3.162278 1.2.3 Ok, but why? You can control the output of your map with these functions: map_lgl map_chr map_int map_dbl map_dfr map_dfc. 1.2.4 See also R for Data Science - 21.5 The map functions 1.3 Mappers 1.3.1 I want to… Create a function on the fly. 1.3.2 Here’s how to: map_dbl(1:10, ~ .x + 2) ## [1] 3 4 5 6 7 8 9 10 11 12 1.3.3 Ok, but why? One sided formulaes, also called mappers, can be created as the .f argument of map. It is build with ~, then .x refers to the element of the list in .x. When mapping on two elements, you can use .x and .y. With more than two elements, refer to them with ..1, ..2, ..3, etc. 1.3.4 See also R for Data Science - 21.5.1 Shortcuts 1.4 map on 2 elements 1.4.1 I want to… map over two lists. 1.4.2 Here’s how to: map2_chr(letters, LETTERS, paste) ## [1] &quot;a A&quot; &quot;b B&quot; &quot;c C&quot; &quot;d D&quot; &quot;e E&quot; &quot;f F&quot; &quot;g G&quot; &quot;h H&quot; &quot;i I&quot; &quot;j J&quot; &quot;k K&quot; ## [12] &quot;l L&quot; &quot;m M&quot; &quot;n N&quot; &quot;o O&quot; &quot;p P&quot; &quot;q Q&quot; &quot;r R&quot; &quot;s S&quot; &quot;t T&quot; &quot;u U&quot; &quot;v V&quot; ## [23] &quot;w W&quot; &quot;x X&quot; &quot;y Y&quot; &quot;z Z&quot; 1.4.3 Ok, but why? map2 and friends (map2 map2_lgl map2_int map2_dbl map2_chr map2_dfr map2_dfc) allows to map over two elements. 1.4.4 See also R for Data Science - 21.7 Mapping over multiple arguments 1.5 map on more elements 1.5.1 I want to… map over more than two lists. 1.5.2 Here’s how to: l &lt;- list(a = 1:3, b = 2:4, c = 3:5) pmap_dbl(l, ~ ..1 + ..2 + ..3) ## [1] 6 9 12 1.5.3 Ok, but why? pmap and friends (pmap_lgl pmap_int pmap_dbl pmap_chr pmap_dfr pmap_dfc) allows to map over more than two elements. 1.5.4 See also R for Data Science - 21.7 Mapping over multiple arguments 1.6 Iteration for side effect 1.6.1 I want to… Iterate only for side effect. 1.6.2 Here’s how to: walk(1:2, plot) 1.6.3 Ok, but why? walk is the silent conterpart of map, but invisible: you call it just for side effects. map_*, map2_*, pwalk and friends also exists. 1.6.4 See also R for Data Science - 21.8 Walk "],
["stats.html", "Chapter 2 Statistics 2.1 Compute the mean 2.2 Running a shapiro test 2.3 Test only numeric columns 2.4 cor.test 2.5 Linear regression 2.6 significant r.squared 2.7 test and validation 2.8 rpart 2.9 Make prediction 2.10 Confusion matrix 2.11 Sensitivity and Specificity", " Chapter 2 Statistics set.seed(2811) 2.1 Compute the mean 2.1.1 I want to… Get the mean of vectors of unequal length. 2.1.2 Here’s how to: numbers &lt;- list(rnorm(10), rnorm(10), rnorm(1000)) trim &lt;- 20 na_rm &lt;- TRUE pmap_dbl(list(numbers, trim, na_rm), ~ mean(..1, ..2,..3)) ## [1] 0.11880200 -0.20132631 0.01946699 2.1.3 Ok, but why? pmap takes a list of list as an input, and send them to the function. In .f, you can refer to the list arguments with their position: here, ..1, ..2 and ..3. 2.1.4 See also 2.2 Running a shapiro test Given the dataset airquality. 2.2.1 I want to… Look for normality on all columns, and know the one which are normal: 2.2.2 Here’s how to: map(airquality, shapiro.test) %&gt;% keep(~ .x$p.value &gt; 0.05) ## $Wind ## ## Shapiro-Wilk normality test ## ## data: .x[[i]] ## W = 0.98575, p-value = 0.1178 2.2.3 Ok, but why? In R, data.frame are lists of vectors of same length. So, you can apply a function the same way you would apply a function on any list. Here, we are mapping a shapiro.test, on all columns, and we keep only the elements with a .x$p.value which is more than 0.05. 2.2.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.3 Test only numeric columns 2.3.1 I want to… Make sure I make my statistical test on numeric values. 2.3.2 Here’s how to: map_if(.x = iris, .p = is.numeric, .f = shapiro.test) ## $Sepal.Length ## ## Shapiro-Wilk normality test ## ## data: .x[[i]] ## W = 0.97609, p-value = 0.01018 ## ## ## $Sepal.Width ## ## Shapiro-Wilk normality test ## ## data: .x[[i]] ## W = 0.98492, p-value = 0.1012 ## ## ## $Petal.Length ## ## Shapiro-Wilk normality test ## ## data: .x[[i]] ## W = 0.87627, p-value = 7.412e-10 ## ## ## $Petal.Width ## ## Shapiro-Wilk normality test ## ## data: .x[[i]] ## W = 0.90183, p-value = 1.68e-08 ## ## ## $Species ## [1] setosa setosa setosa setosa setosa setosa ## [7] setosa setosa setosa setosa setosa setosa ## [13] setosa setosa setosa setosa setosa setosa ## [19] setosa setosa setosa setosa setosa setosa ## [25] setosa setosa setosa setosa setosa setosa ## [31] setosa setosa setosa setosa setosa setosa ## [37] setosa setosa setosa setosa setosa setosa ## [43] setosa setosa setosa setosa setosa setosa ## [49] setosa setosa versicolor versicolor versicolor versicolor ## [55] versicolor versicolor versicolor versicolor versicolor versicolor ## [61] versicolor versicolor versicolor versicolor versicolor versicolor ## [67] versicolor versicolor versicolor versicolor versicolor versicolor ## [73] versicolor versicolor versicolor versicolor versicolor versicolor ## [79] versicolor versicolor versicolor versicolor versicolor versicolor ## [85] versicolor versicolor versicolor versicolor versicolor versicolor ## [91] versicolor versicolor versicolor versicolor versicolor versicolor ## [97] versicolor versicolor versicolor versicolor virginica virginica ## [103] virginica virginica virginica virginica virginica virginica ## [109] virginica virginica virginica virginica virginica virginica ## [115] virginica virginica virginica virginica virginica virginica ## [121] virginica virginica virginica virginica virginica virginica ## [127] virginica virginica virginica virginica virginica virginica ## [133] virginica virginica virginica virginica virginica virginica ## [139] virginica virginica virginica virginica virginica virginica ## [145] virginica virginica virginica virginica virginica virginica ## Levels: setosa versicolor virginica 2.3.3 Ok, but why? map_if runs .f only if the .x verifies the condition .p. 2.3.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.4 cor.test 2.4.1 I want to… Make a bulk cor.test of all my variables. 2.4.2 Here’s how to: library(tidystringdist) # Works since v0.1.2 comb &lt;- tidy_comb_all(names(airquality)) pmap(comb, ~ cor.test(airquality[[.x]], airquality[[.y]])) %&gt;% map_df(broom::tidy) %&gt;% cbind(comb, .) %&gt;% select(V1:parameter) V1 V2 estimate statistic p.value parameter Ozone Solar.R 0.3483417 3.8797948 0.0001793 109 Ozone Wind -0.6015465 -8.0401299 0.0000000 114 Ozone Temp 0.6983603 10.4177242 0.0000000 114 Ozone Month 0.1645193 1.7808517 0.0776001 114 Ozone Day -0.0132256 -0.1412236 0.8879425 114 Solar.R Wind -0.0567917 -0.6826017 0.4959552 144 Solar.R Temp 0.2758403 3.4436863 0.0007518 144 Solar.R Month -0.0753008 -0.9061819 0.3663534 144 Solar.R Day -0.1502750 -1.8240128 0.0702234 144 Wind Temp -0.4579879 -6.3308351 0.0000000 151 Wind Month -0.1782926 -2.2265711 0.0274562 151 Wind Day 0.0271809 0.3341280 0.7387466 151 Temp Month 0.4209473 5.7025370 0.0000001 151 Temp Day -0.1305932 -1.6186176 0.1076164 151 Month Day -0.0079618 -0.0978389 0.9221900 151 2.4.3 Ok, but why? comb is a table containing all combinations of the names of the columns. What we do is mapping a cor.test on all these combinations by extracting, each time, the column as a vector, with airquality[[.x]] and airquality[[.y]]. pmap allows to use a list as a signe input. 2.4.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.5 Linear regression 2.5.1 I want to… Get the r.squared of each of the possible lm of airquality combinations. 2.5.2 Here’s how to: res &lt;- pmap(comb, ~ lm(airquality[[.x]] ~ airquality[[.y]])) get_rsquared &lt;- compose(as_mapper(~ .x$r.squared), summary) map_dbl(res, get_rsquared) ## [1] 1.213419e-01 3.618582e-01 4.877072e-01 2.706660e-02 1.749177e-04 ## [6] 3.225293e-03 7.608786e-02 5.670205e-03 2.258257e-02 2.097529e-01 ## [11] 3.178824e-02 7.388015e-04 1.771966e-01 1.705458e-02 6.338966e-05 2.5.3 Ok, but why? We’re building a model of all combinations with pmap, just as before with cor.test. Then, the get_rsquared function is a composition of extracting the r.squared of the summary of a lm result. compose(x, y) allows to build x(y()). Here, we are combining a mapper extracting the r.squared element out of the summary() of a lm. 2.5.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.6 significant r.squared 2.6.1 I want to… Know if some r.square are above O.5 : 2.6.2 Here’s how to: res &lt;- pmap(comb, ~ lm(airquality[[.x]] ~ airquality[[.y]])) get_rsquared &lt;- compose(as_mapper(~ .x$r.squared), summary) map_dbl(res, get_rsquared) %&gt;% some(~ .x &gt; 0.5) ## [1] FALSE 2.6.3 Ok, but why? some checks if any of the input validate the condition. 2.6.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.7 test and validation 2.7.1 I want to… Create 20 test and validation datasets. 2.7.2 Here’s how to: # From http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv titanic &lt;- readr::read_csv(&quot;titanic.csv&quot;) train &lt;- rerun(20, sample_frac(titanic, size = 0.8)) validation &lt;- map(train, ~ anti_join(titanic, .x)) 2.7.3 Ok, but why? rerun runs the sampling 20 times. To obtain the 20 validation sets, we anti-join each elements of the train list with the original dataframe. That way, train[1] + validation[1] = titanic, train[2] + validation[2] = titanic, etc 2.7.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.8 rpart 2.8.1 I want to… Create 20 rpart, modeled on my 20 elements in the test list. 2.8.2 Here’s how to: library(rpart) rpart_pimped &lt;- partial(rpart, formula = survived ~ sex, method = &quot;class&quot;) res &lt;- map(train, rpart_pimped) res[[1]] ## n= 1047 ## ## node), split, n, loss, yval, (yprob) ## * denotes terminal node ## ## 1) root 1047 408 0 (0.6103152 0.3896848) ## 2) sex=male 666 127 0 (0.8093093 0.1906907) * ## 3) sex=female 381 100 1 (0.2624672 0.7375328) * 2.8.3 Ok, but why? partial allows to build a prefil function, which is then mapped on each element. 2.8.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.9 Make prediction 2.9.1 I want to… Make prediction based on my models 2.9.2 Here’s how to: prediction &lt;- map2(validation, res, ~ predict(.y, .x, type = &quot;class&quot;)) w_prediction &lt;- map2(validation, prediction, ~ mutate(.x, prediction = .y)) 2.9.3 Ok, but why? map2 allows to map on two arguments. 2.9.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.10 Confusion matrix 2.10.1 I want to… Create a conf matrix on all these results: 2.10.2 Here’s how to: library(caret) conf_mats &lt;- map(w_prediction, ~ confusionMatrix(.x$prediction, .x$survived)) 2.10.3 Ok, but why? You can use .x as many times as you want in .f. 2.10.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics 2.11 Sensitivity and Specificity 2.11.1 I want to… Detect which models have a specificity above 0.7 and sensitivity above 0.85 (randomly chosen numbers). 2.11.2 Here’s how to: keep_index &lt;- function(.x, .p, ...) { sel &lt;- purrr:::probe(.x, .p, ...) which(sel) } sens &lt;- map_dbl(conf_mats, ~ .x$byClass[&quot;Sensitivity&quot;]) %&gt;% keep_index(~ .x &gt; 0.85) spec &lt;- map_dbl(conf_mats, ~ .x$byClass[&quot;Specificity&quot;]) %&gt;% keep_index(~ .x &gt; 0.7) keep(sens, map_lgl(sens, ~ .x %in% spec)) ## [1] 2 5 2.11.3 Ok, but why? We have created a function that returns the position of elements that validates a condition. sens is the vector containing the position with sensitivity above 0.85, spec the vector for specificity above 0.7. Then, we pass to keep a vector of logical built with map_lgl. This vector tells if each elements of sens is or isn’t in spec. 2.11.4 See also A Crazy Little Thing Called {purrr} - Part 6 : doing statistics "],
["webmining.html", "Chapter 3 Webmining 3.1 Status code 3.2 Check status code 3.3 Scrape a list of urls which may fail 3.4 Getting h2 3.5 JSON with many levels 3.6 Several API call", " Chapter 3 Webmining 3.1 Status code 3.1.1 I want to… Create a status code checker. 3.1.2 Here’s how to library(httr) get_status &lt;- compose(status_code, GET) get_status(&quot;colinfay.me&quot;) ## [1] 200 3.1.3 Ok, but why? compose(y, x) composes a function that will do y(x()). So here, get_status(&quot;url&quot;) will do status_code(GET(&quot;url&quot;)). 3.1.4 See also 3.2 Check status code 3.2.1 I want to… Check for http status code for a list of pages. 3.2.2 Here’s how to urls &lt;- c(&quot;http://colinfay.me&quot;, &quot;http://thinkr.fr&quot;, &quot;reallynotanadress&quot;) get_status &lt;- compose(status_code, GET) map(urls, get_status) %&gt;% every(~ .x == 200) ## [1] FALSE 3.2.3 Ok, but why? 200 is a status code that indicates that the connexion went smoothly. The every function here checks if all the status code we just GET are equal to 200. 3.2.4 See also 3.3 Scrape a list of urls which may fail 3.3.1 I want to… Launch a read_html function on a list of webpages, and some may throw an error. The difference with the function we saw previously ? # http status code error GET(&quot;notexistingurl&quot;) ## Response [http://notexistingurl/] ## Date: 2018-01-19 21:49 ## Status: 403 ## Content-Type: text/html; charset=iso-8859-1 ## Size: 202 B ## &lt;!DOCTYPE HTML PUBLIC &quot;-//IETF//DTD HTML 2.0//EN&quot;&gt; ## &lt;html&gt;&lt;head&gt; ## &lt;title&gt;403 Forbidden&lt;/title&gt; ## &lt;/head&gt;&lt;body&gt; ## &lt;h1&gt;Forbidden&lt;/h1&gt; ## &lt;p&gt;You don&#39;t have permission to access / ## on this server.&lt;/p&gt; ## &lt;/body&gt;&lt;/html&gt; # Error because host doesn&#39;t exist GET(&quot;notexistingurl.org&quot;) ## Error in curl::curl_fetch_memory(url, handle = handle): Could not resolve host: notexistingurl.org 3.3.2 Here’s how to library(rvest) urls &lt;- c(&quot;http://colinfay.me&quot;, &quot;http://thinkr.fr&quot;, &quot;reallynotanadress&quot;) possible_read &lt;- possibly(read_html, otherwise = NULL) map(urls, possible_read) %&gt;% set_names(urls) %&gt;% compact() ## $`http://colinfay.me` ## {xml_document} ## &lt;html lang=&quot;en&quot; class=&quot;no-js&quot;&gt; ## [1] &lt;head&gt;\\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset= ... ## [2] &lt;body class=&quot;layout--home&quot;&gt;\\n\\n &lt;!--[if lt IE 9]&gt;\\n&lt;div class=&quot;no ... ## ## $`http://thinkr.fr` ## {xml_document} ## &lt;html class=&quot;no-js&quot; lang=&quot;fr-FR&quot;&gt; ## [1] &lt;head&gt;\\n&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset= ... ## [2] &lt;body class=&quot;home page-template-default page page-id-35625 do-etfw f ... 3.3.3 Ok, but why possibly turns a function into another function that returns what is defined in otherwise in case of failure. Here, we chose to return NULL. compact() removes all the elements from a list which are NULL. 3.3.4 See also R for Data Science - 21.6 Dealing with failure 3.4 Getting h2 3.4.1 I want to… Get the h2s from a list of urls. 3.4.2 Here’s how to get_h2 &lt;- compose(html_text, as_mapper(~ html_nodes(.x, &quot;h2&quot;)), read_html) urls &lt;- c(&quot;http://colinfay.me&quot;, &quot;http://thinkr.fr&quot;) map(urls, get_h2) %&gt;% set_names(urls) ## $`http://colinfay.me` ## [1] &quot;On the blog : &quot; ## [2] &quot;\\n \\n Combining the new {rtweet} and {tidytext}\\n\\n \\n &quot; ## [3] &quot;\\n \\n [How to] Include a dancing banana in your R package documentation\\n\\n \\n &quot; ## [4] &quot;\\n \\n Some random R benchmarks\\n\\n \\n &quot; ## [5] &quot;\\n \\n {attempt} is now on CRAN\\n\\n \\n &quot; ## [6] &quot;\\n \\n A Crazy Little Thing Called {purrr} - Part 6 : doing statistics\\n\\n \\n &quot; ## ## $`http://thinkr.fr` ## [1] &quot;Conseil, développement et formation au logiciel R&quot; ## [2] &quot;Formez-vous au logiciel R !&quot; ## [3] &quot;\\r\\n\\t\\tLe logo ThinkR créé avec la librairie {sf}\\r\\n\\t&quot; ## [4] &quot;\\r\\n\\t\\tR de jeu #2 : Happy new yeaR\\r\\n\\t&quot; ## [5] &quot;\\r\\n\\t\\tDe retour de Budapest\\r\\n\\t&quot; ## [6] &quot;\\r\\n\\t\\tR de jeu #1 : API, dataviz, et statistiques\\r\\n\\t&quot; ## [7] &quot;\\r\\n\\t\\tforcats, forcats, vous avez dit forcats ?\\r\\n\\t&quot; ## [8] &quot;\\r\\n\\t\\tText mining et topic modeling avec R\\r\\n\\t&quot; ## [9] &quot;\\r\\n\\t\\tÀ la découverte de {rvest}\\r\\n\\t&quot; ## [10] &quot;\\r\\n\\t\\tPremiers pas en Machine Learning avec R. Volume 4 : random forest\\r\\n\\t&quot; ## [11] &quot;\\r\\n\\t\\tAu menu du jour : {R6} — Partie 2\\r\\n\\t&quot; 3.4.3 Ok, but why? We are composing an h2 extractor by combining read_html, html_nodes and html_text. We then map this extractor to a list of urls, before setting the names of the results with the set_names function. 3.4.4 See also 3.5 JSON with many levels 3.5.1 I want to… Extract all the test1 results. 3.5.2 Here’s how to: map(json_file, ~ purrr::pluck(.x, &quot;Res&quot;, &quot;test1&quot;)) ## $obs1 ## [1] &quot;17&quot; ## ## $obs2 ## [1] &quot;12&quot; 3.5.3 Ok, but why What we called before is a shortcut for map(file, ~ pluck(.x, &quot;id&quot;). That shortcut works on the first level of the list. If you need to go deeper, you need to explicitely specify the pluck call. Be careful, there is also a pluck in {rvest} that doesn’t behave exactly as the pluck from {purrr}. map(json_file, ~ rvest::pluck(.x, &quot;Res&quot;, &quot;test1&quot;)) ## Error in FUN(X[[i]], ...): indice hors limites 3.5.4 See also 3.6 Several API call 3.6.1 I want to… Make a series of API calls 3.6.2 Here’s how to: library(attempt) library(curl) caller &lt;- function(x){ # verify internet connexion stop_if_not(has_internet(), msg = &quot;You should have internet to do that&quot;) res &lt;- GET(url = &quot;https://geo.api.gouv.fr/communes&quot;, query = list(nom = x)) res$content %&gt;% rawToChar() %&gt;% jsonlite::fromJSON(simplifyDataFrame = TRUE) } city &lt;- c(&quot;Rennes&quot;,&quot;Vannes&quot;,&quot;Brest&quot;) map_df(city, caller) nom code codeDepartement codeRegion codesPostaux population _score Rennes 35238 35 53 35000, 35200, 35700 211373 1.0000000 Rennes-le-Château 11309 11 76 11190 58 0.7761594 Rennes-les-Bains 11310 11 76 11190 258 0.7583585 Rennes-sur-Loue 25488 25 27 25440 88 0.6743168 Rennes-en-Grenouilles 53189 53 52 53110 117 0.6239261 Vannes 56260 56 53 56000 53032 1.0000000 Vannes-le-Châtel 54548 54 44 54112 579 0.7510264 Pouy-sur-Vannes 10301 10 44 10290 145 0.6873107 Saulxures-lès-Vannes 54496 54 44 54170 363 0.6820142 Vannes-sur-Cosson 45331 45 24 45510 589 0.6652302 Brest 29019 29 53 29200 139386 0.7182376 Brestot 27110 27 28 27350 518 0.6957980 Esboz-Brest 70216 70 27 70300 485 0.4918154 3.6.3 Ok, but why? Here, we are calling an API which returns a JSON object that can be easily turned into a df with {jsonlite}. So we choose to use map_df to return a simple data.frame of the three results. 3.6.4 See also "],
["tm.html", "Chapter 4 Text Mining 4.1 Build regex 4.2 Regex extraction 4.3 Collapse a list of words", " Chapter 4 Text Mining 4.1 Build regex 4.1.1 I want to… Automatically build a regex with or | 4.1.2 Here’s how to: regex_build &lt;- function(...){ reduce(list(...), ~ paste(.x, .y, sep = &quot;|&quot;)) } regex_build(&quot;one&quot;,&quot;two&quot;,&quot;three&quot;, &quot;four&quot;) ## [1] &quot;one|two|three|four&quot; 4.1.3 Ok, but why? reduce turns a list into one value by recursively applying a binary function to the list. In other words, reduce(list(&quot;one&quot;,&quot;two&quot;,&quot;three&quot;), ~ paste(.x, .y, sep = &quot;|&quot;)) does paste(&quot;one&quot;, paste(&quot;two&quot;, paste(&quot;three&quot;, &quot;four&quot;, sep = &quot;|&quot;), sep = &quot;|&quot;), sep = &quot;|&quot;). 4.1.4 See also 4.2 Regex extraction 4.2.1 I want to… Extract the elements from a list of words that match a regex 4.2.2 Here’s how to: # Random words from https://www.randomlists.com/random-words words &lt;- c(&quot;copper&quot;, &quot;explain&quot;, &quot;ill-fated&quot;, &quot;truck&quot;, &quot;neat&quot;,&quot;unite&quot;,&quot;branch&quot;,&quot;educated&quot;,&quot;tenuous&quot;, &quot;hum&quot;,&quot;decisive&quot;,&quot;notice&quot;) # Extract words that end with a &quot;e&quot; my_regex &lt;- &quot;e$&quot; keep(words, ~ grepl(my_regex, .x)) ## [1] &quot;unite&quot; &quot;decisive&quot; &quot;notice&quot; 4.2.3 Ok, but why? keep only keeps the element matching the predicate. Here, we’re using grepl, that returns TRUE or FALSE if the expression is found in the string. 4.2.4 See also 4.3 Collapse a list of words Given the following list of hashtags: hash &lt;- list(tweet1 = c(&quot;#RStats&quot;, &quot;#Datascience&quot;), tweet2 = c(&quot;#RStats&quot;, &quot;#BigData&quot;)) 4.3.1 I want to… Turn my list of words into a simple vector. 4.3.2 Here’s how to: simplify(hash) %&gt;% paste(collapse = &quot; &quot;) ## [1] &quot;#RStats #Datascience #RStats #BigData&quot; 4.3.3 Ok, but why? Simplify turns a list of n*m elements into a vector of lenght n*m. We then paste all the elements together, using the collapse argument from paste. 4.3.4 See also "],
["optim.html", "Chapter 5 Code Optimisation 5.1 Compose functions 5.2 Prefilled functions 5.3 Negate a function 5.4 Negate a function", " Chapter 5 Code Optimisation 5.1 Compose functions 5.1.1 I want to… Write a function that wraps other functions. 5.1.2 Here’s how to: library(broom) tidy_lm &lt;- compose(tidy, lm) tidy_lm(Sepal.Length ~ Species, data = iris) term estimate std.error statistic p.value (Intercept) 5.006 0.0728022 68.761639 0 Speciesversicolor 0.930 0.1029579 9.032819 0 Speciesvirginica 1.582 0.1029579 15.365506 0 5.1.3 Ok, but why? compose(y, x) composes a function that will do y(x()). 5.1.4 See also A Crazy Little Thing Called {purrr} - Part 5: code optimization 5.2 Prefilled functions 5.2.1 I want to… Prefill a function so that I won’t have to specify the arguments any time I use it. 5.2.2 Here’s how to: mean_na_rm &lt;- partial(mean, na.rm = TRUE) mean_na_rm(airquality$Ozone) ## [1] 42.12931 5.2.3 Ok, but why? partial(f, args = &quot;x&quot;) returns a function with a prefilled function with args = &quot;x&quot;. 5.2.4 See also A Crazy Little Thing Called {purrr} - Part 5: code optimization 5.3 Negate a function 5.3.1 I want to… Inverse what a function does. 5.3.2 Here’s how to: is_not_numeric &lt;- negate(is.numeric) is_not_numeric(&quot;this&quot;) ## [1] TRUE 5.3.3 Ok, but why? negate(f) returns a function that does !f(...). 5.3.4 See also 5.4 Negate a function 5.4.1 I want to… Change what input my function can take. 5.4.2 Here’s how to: lifted_is_na &lt;- lift_ld(is.na) lifted_is_na(1,2,3,NA) ## [1] FALSE FALSE FALSE TRUE 5.4.3 Ok, but why? The lift_* family of functions change the type of input of other function. 5.4.4 See also "],
["wrangling.html", "Chapter 6 Data Wrangling 6.1 Read csvs 6.2 Remove the NA 6.3 List append 6.4 Position matching 6.5 Cut a list", " Chapter 6 Data Wrangling 6.1 Read csvs 6.1.1 I want to… Read a list of csv and turn them all into a data frame. 6.1.2 Here’s how to: files &lt;- list.files(pattern = &quot;csv&quot;, full.names = TRUE) %&gt;% set_names(basename(.)) full &lt;- map_df(files, readr::read_csv, .id = &quot;file&quot;) 6.1.3 Ok, but why? map_df maps the read_csv on all the files, and returns a data.frame. The .id is used to keep track of the original file. 6.1.4 See also 6.2 Remove the NA 6.2.1 I want to… Remove the NA from my list. 6.2.2 Here’s how to: l &lt;- list(1, NA, &quot;a&quot;, &quot;b&quot;, NA) discard(l, is.na) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] &quot;a&quot; ## ## [[3]] ## [1] &quot;b&quot; 6.2.3 Ok, but why? discard is the opposite of keep, and removes all the elements that validate a condition. 6.2.4 See also 6.3 List append 6.3.1 I want to… Add an element at the end of all my sublists. 6.3.2 Here’s how to: l &lt;- list(list(1:10, 1:20), list(20:30, 40:50)) modify_depth(l, 2, ~ prepend(.x, sum(.x))) ## [[1]] ## [[1]][[1]] ## [1] 55 1 2 3 4 5 6 7 8 9 10 ## ## [[1]][[2]] ## [1] 210 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## [18] 17 18 19 20 ## ## ## [[2]] ## [[2]][[1]] ## [1] 275 20 21 22 23 24 25 26 27 28 29 30 ## ## [[2]][[2]] ## [1] 495 40 41 42 43 44 45 46 47 48 49 50 6.3.3 Ok, but why? modify_depth allows to map function in sublists at a given depth. prepend adds a element to the list at a givent index. If no index is given, the element is put at the beggining of the list. 6.3.4 See also 6.4 Position matching 6.4.1 I want to… Find the first argument that matches a condition. 6.4.2 Here’s how to: l &lt;- 22:143 detect_index(l, ~ sqrt(.x) == 9) ## [1] 60 6.4.3 Ok, but why? detect_index returns the position of the first argument matching the condition. detect alone returns the value. You can pass the .right argument to these function, so that the search starts from the end of the list. 6.4.4 See also 6.5 Cut a list 6.5.1 I want to… Takes all the arguments from a list until the condition is met. 6.5.2 Here’s how to: l &lt;- 22:143 head_while(l, ~ sqrt(.x) &lt; 9) ## [1] 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 ## [24] 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 ## [47] 68 69 70 71 72 73 74 75 76 77 78 79 80 6.5.3 Ok, but why? head_while, and its counterpart tail_while, take a list and perform a head or tail until a predicate is validated. 6.5.4 See also "]
]
